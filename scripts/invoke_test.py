#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-Embedding-0.6B æ‰¹é‡åµŒå…¥æµ‹è¯•è„šæœ¬
æµ‹è¯• 64 æ¡æœ€å¤§æ‰¹é‡å¤„ç†èƒ½åŠ›
"""

import requests
import numpy as np
from typing import List, Dict

API_URL = "http://localhost:8000/v1/embeddings"
MODEL_ID = "Qwen3-Embedding-0.6B"


def generate_test_texts(count: int = 64) -> List[str]:
    """ç”ŸæˆæŒ‡å®šæ•°é‡çš„æµ‹è¯•æ–‡æœ¬ï¼ˆæ¨¡æ‹Ÿä¸åŒåœºæ™¯ï¼‰"""

    templates = [
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜{field}è¡Œä¸šçš„è¿ä½œæ–¹å¼ï¼Œç‰¹åˆ«æ˜¯åœ¨{application}æ–¹é¢ã€‚",
        "æœºå™¨å­¦ä¹ æ¨¡å‹é€šè¿‡{method}æŠ€æœ¯ï¼Œå®ç°äº†{result}çš„æ˜¾è‘—æå‡ã€‚",
        "æ·±åº¦å­¦ä¹ åœ¨{domain}é¢†åŸŸçš„åº”ç”¨ï¼Œè§£å†³äº†{problem}è¿™ä¸€é•¿æœŸéš¾é¢˜ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ä½¿å¾—{task}å˜å¾—æ›´åŠ é«˜æ•ˆå’Œå‡†ç¡®ã€‚",
        "è®¡ç®—æœºè§†è§‰ç³»ç»Ÿèƒ½å¤Ÿè¯†åˆ«{object}ï¼Œå‡†ç¡®ç‡è¾¾åˆ°{accuracy}ä»¥ä¸Šã€‚",
        "å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨{environment}ä¸­è¡¨ç°å‡ºè‰²ï¼Œè·å¾—äº†{reward}çš„å¥–åŠ±åˆ†æ•°ã€‚",
        "ç¥ç»ç½‘ç»œæ¶æ„{architecture}åœ¨{dataset}æ•°æ®é›†ä¸Šåˆ›é€ äº†æ–°çš„è®°å½•ã€‚",
        "æ•°æ®æŒ–æ˜æŠ€æœ¯ä»{source}ä¸­æå–æœ‰ä»·å€¼çš„{information}ï¼Œç”¨äºå†³ç­–æ”¯æŒã€‚",
    ]

    fields = ["åŒ»ç–—", "é‡‘è", "æ•™è‚²", "åˆ¶é€ ", "äº¤é€š", "é›¶å”®", "å†œä¸š", "èƒ½æº"]
    applications = ["è¯Šæ–­è¾…åŠ©", "é£é™©è¯„ä¼°", "ä¸ªæ€§åŒ–æ•™å­¦", "è´¨é‡æ§åˆ¶", "è‡ªåŠ¨é©¾é©¶", "æ¨èç³»ç»Ÿ", "äº§é‡é¢„æµ‹", "æ™ºèƒ½ç”µç½‘"]
    methods = ["è¿ç§»å­¦ä¹ ", "è”é‚¦å­¦ä¹ ", "å¯¹æ¯”å­¦ä¹ ", "è‡ªç›‘ç£å­¦ä¹ ", "å…ƒå­¦ä¹ ", "å¤šä»»åŠ¡å­¦ä¹ ", "çŸ¥è¯†è’¸é¦", "æ¨¡å‹å‹ç¼©"]
    domains = ["åŸºå› ç»„å­¦", "æ°”å€™ç§‘å­¦", "ææ–™ç§‘å­¦", "å¤©æ–‡å­¦", "åŒ–å­¦", "ç‰©ç†å­¦", "ç”Ÿç‰©å­¦", "åœ°çƒç§‘å­¦"]

    texts = []
    for i in range(count):
        template = templates[i % len(templates)]
        text = template.format(
            field=fields[i % len(fields)],
            application=applications[i % len(applications)],
            method=methods[i % len(methods)],
            result=f"{85 + (i % 15)}%",
            domain=domains[i % len(domains)],
            problem=f"ä¼ ç»Ÿæ–¹æ³•æ•ˆç‡ä½ä¸‹çš„é—®é¢˜{i}",
            task=f"æ–‡æœ¬ç†è§£å’Œç”Ÿæˆä»»åŠ¡ç±»å‹{i}",
            object=f"å¤æ‚åœºæ™¯ä¸­çš„ç›®æ ‡ç‰©ä½“ç±»åˆ«{i % 20}",
            accuracy=f"{90 + (i % 10)}%",
            environment=f"åŠ¨æ€å˜åŒ–ç¯å¢ƒç‰ˆæœ¬{i % 10}",
            reward=f"{1000 + i * 100}",
            architecture=f"Transformerå˜ä½“æ¶æ„{i % 8}",
            dataset=f"å¤§è§„æ¨¡è¡Œä¸šæ•°æ®é›†{i % 12}",
            source=f"å¤šæºå¼‚æ„æ•°æ®æº{i % 6}",
            information=f"å…³é”®ä¸šåŠ¡æ´å¯Ÿä¿¡æ¯{i}"
        )
        texts.append(text)

    return texts


def batch_embed(texts: List[str]) -> Dict:
    """è°ƒç”¨ API è·å–æ‰¹é‡åµŒå…¥"""

    payload = {
        "input": texts,  # ç›´æ¥ä¼ å…¥åˆ—è¡¨
        "model": MODEL_ID,
        "encoding_format": "float",
        "normalize": True
    }

    try:
        response = requests.post(API_URL, json=payload, timeout=120)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e.response, 'text'):
            print(f"é”™è¯¯è¯¦æƒ…: {e.response.text}")
        raise


def verify_embeddings(embeddings: List[List[float]], expected_count: int, expected_dim: int = 1024):
    """éªŒè¯åµŒå…¥ç»“æœ"""

    print(f"\n{'=' * 50}")
    print("ğŸ“Š åµŒå…¥ç»“æœéªŒè¯")
    print(f"{'=' * 50}")

    # 1. æ•°é‡éªŒè¯
    actual_count = len(embeddings)
    assert actual_count == expected_count, f"æ•°é‡ä¸åŒ¹é…: æœŸæœ› {expected_count}, å®é™… {actual_count}"
    print(f"âœ… æ•°é‡éªŒè¯é€šè¿‡: {actual_count} æ¡åµŒå…¥")

    # 2. ç»´åº¦éªŒè¯
    actual_dim = len(embeddings[0])
    assert actual_dim == expected_dim, f"ç»´åº¦ä¸åŒ¹é…: æœŸæœ› {expected_dim}, å®é™… {actual_dim}"
    print(f"âœ… ç»´åº¦éªŒè¯é€šè¿‡: {actual_dim} ç»´å‘é‡")

    # 3. L2 å½’ä¸€åŒ–éªŒè¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦åŸºç¡€ï¼‰
    norms = [np.linalg.norm(emb) for emb in embeddings]
    avg_norm = np.mean(norms)
    std_norm = np.std(norms)

    print(f"âœ… L2 å½’ä¸€åŒ–éªŒè¯: å¹³å‡èŒƒæ•° = {avg_norm:.6f} (æ ‡å‡†å·®: {std_norm:.8f})")
    assert 0.99 < avg_norm < 1.01, "L2 å½’ä¸€åŒ–éªŒè¯å¤±è´¥ï¼ŒèŒƒæ•°åº”æ¥è¿‘ 1.0"

    # 4. ç›¸ä¼¼åº¦è®¡ç®—ç¤ºä¾‹ï¼ˆå‰ 3 æ¡æ–‡æœ¬çš„ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µï¼‰
    print(f"\nğŸ“ ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆå‰ 5 æ¡æ ·æœ¬ï¼‰:")
    emb_matrix = np.array(embeddings[:5])
    # ç”±äºå·²å½’ä¸€åŒ–ï¼Œç‚¹ç§¯å³ä½™å¼¦ç›¸ä¼¼åº¦
    similarity_matrix = np.dot(emb_matrix, emb_matrix.T)

    print("       ", end="")
    for i in range(5):
        print(f"æ–‡æœ¬{i:2d}  ", end="")
    print()

    for i in range(5):
        print(f"æ–‡æœ¬{i:2d}  ", end="")
        for j in range(5):
            sim = similarity_matrix[i, j]
            if i == j:
                print(f" {sim:.3f}* ", end="")  # å¯¹è§’çº¿åº”ä¸º 1.0
            else:
                print(f" {sim:.3f}  ", end="")
        print()
    print("* å¯¹è§’çº¿å€¼ä¸º 1.000ï¼ˆæ–‡æœ¬ä¸è‡ªèº«çš„ç›¸ä¼¼åº¦ï¼‰")

    return {
        "count": actual_count,
        "dimensions": actual_dim,
        "avg_norm": float(avg_norm),
        "similarity_matrix": similarity_matrix.tolist()
    }


def main():
    print("ğŸš€ Qwen3-Embedding-0.6B æ‰¹é‡åµŒå…¥æµ‹è¯•")
    print(f"{'=' * 50}")
    print(f"ç›®æ ‡: æµ‹è¯•æœ€å¤§æ‰¹é‡ 64 æ¡æ–‡æœ¬çš„åµŒå…¥èƒ½åŠ›")
    print(f"APIç«¯ç‚¹: {API_URL}")
    print(f"{'=' * 50}\n")

    # ç”Ÿæˆ 64 æ¡æµ‹è¯•æ–‡æœ¬
    test_texts = generate_test_texts(count=64)
    print(f"ğŸ“ å·²ç”Ÿæˆ {len(test_texts)} æ¡æµ‹è¯•æ–‡æœ¬ï¼ˆå†…å®¹ä¸é‡å¤ï¼‰")
    print(f"   ç¤ºä¾‹æ–‡æœ¬1: {test_texts[0][:50]}...")
    print(f"   ç¤ºä¾‹æ–‡æœ¬32: {test_texts[31][:50]}...")
    print(f"   ç¤ºä¾‹æ–‡æœ¬64: {test_texts[63][:50]}...")

    # æ‰§è¡Œæ‰¹é‡åµŒå…¥è¯·æ±‚
    print(f"\nâ³ å‘é€æ‰¹é‡åµŒå…¥è¯·æ±‚ï¼ˆ64æ¡ï¼‰...")
    result = batch_embed(test_texts)

    # è§£æç»“æœ
    embeddings = [item["embedding"] for item in result["data"]]
    usage = result["usage"]

    print(f"\nâœ… è¯·æ±‚æˆåŠŸ!")
    print(f"   å¤„ç†æ—¶é—´: {usage['processing_time_ms']:.2f} ms")
    print(f"   æ€» Token æ•°: {usage['total_tokens']}")

    # éªŒè¯åµŒå…¥è´¨é‡
    stats = verify_embeddings(embeddings, expected_count=64)

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'=' * 50}")
    print("ğŸ“ˆ æ‰¹é‡åµŒå…¥ç»Ÿè®¡")
    print(f"{'=' * 50}")
    print(f"æ‰¹é‡å¤§å°: {stats['count']} æ¡")
    print(f"å‘é‡ç»´åº¦: {stats['dimensions']} ç»´")
    print(f"å½’ä¸€åŒ–çŠ¶æ€: L2 èŒƒæ•° â‰ˆ {stats['avg_norm']:.4f} (å·²å½’ä¸€åŒ–)")
    print(f"æ•°æ®æ ¼å¼: Float32 æ•°ç»„")
    print(f"é€‚ç”¨åœºæ™¯: è¯­ä¹‰æœç´¢ã€æ–‡æœ¬èšç±»ã€ç›¸ä¼¼åº¦åŒ¹é…")

    print(f"\n{'=' * 50}")
    print("âœ¨ æµ‹è¯•å®Œæˆï¼64 æ¡æ‰¹é‡åµŒå…¥åŠŸèƒ½æ­£å¸¸")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    main()